{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据\n",
    "def load_data(filename,skip_no_answer=False):\n",
    "        # Load JSON lines\n",
    "    print('loading')\n",
    "    with open(filename) as f:\n",
    "        examples = [json.loads(line) for line in f]\n",
    "    # Make case insensitive?\n",
    "    print('insensitiving')\n",
    "    for ex in tqdm(examples):\n",
    "        ex['question'] = [w.lower() for w in ex['question']]\n",
    "        ex['document'] = [w.lower() for w in ex['document']]\n",
    "    # Skip unparsed (start/end) examples\n",
    "    examples = [ex for ex in examples if len(ex['answers']) > 0]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 8246/10570 [00:00<00:00, 42531.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insensitiving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:00<00:00, 39528.51it/s]\n"
     ]
    }
   ],
   "source": [
    "train_examples=load_data('./dev-v1.1-processed-corenlp.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['w', 'h', 'i', 'c', 'h'],\n",
       " ['n', 'f', 'l'],\n",
       " ['t', 'e', 'a', 'm'],\n",
       " ['r', 'e', 'p', 'r', 'e', 's', 'e', 'n', 't', 'e', 'd'],\n",
       " ['t', 'h', 'e'],\n",
       " ['a', 'f', 'c'],\n",
       " ['a', 't'],\n",
       " ['s', 'u', 'p', 'e', 'r'],\n",
       " ['b', 'o', 'w', 'l'],\n",
       " ['5', '0'],\n",
       " ['?']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_tokens=train_examples[0]['question']\n",
    "[list(token) for token in ques_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解析样本\n",
    "def vectorize(ex, model, single_answer=False):\n",
    "    args = model.args\n",
    "    word_dict = model.word_dict\n",
    "    feature_dict = model.feature_dict\n",
    "    \n",
    "    # Index words\n",
    "    document = torch.LongTensor([word_dict[w] for w in ex['document']])\n",
    "    question = torch.LongTensor([word_dict[w] for w in ex['question']])\n",
    "    \n",
    "    # Create extra features vector\n",
    "    if len(feature_dict) > 0:\n",
    "        features = torch.zeros(len(ex['document']), len(feature_dict))\n",
    "    else:\n",
    "        features = None\n",
    "    # f_{exact_match}\n",
    "    if args.use_in_question:\n",
    "        q_words_cased = {w for w in ex['question']}\n",
    "        q_words_uncased = {w.lower() for w in ex['question']}\n",
    "        q_lemma = {w for w in ex['qlemma']} if args.use_lemma else None\n",
    "        for i in range(len(ex['document'])):\n",
    "            if ex['document'][i] in q_words_cased:\n",
    "                features[i][feature_dict['in_question']] = 1.0\n",
    "            if ex['document'][i].lower() in q_words_uncased:\n",
    "                features[i][feature_dict['in_question_uncased']] = 1.0\n",
    "            if q_lemma and ex['lemma'][i] in q_lemma:\n",
    "                features[i][feature_dict['in_question_lemma']] = 1.0\n",
    "    # f_{token} (POS)\n",
    "    if args.use_pos:\n",
    "        for i, w in enumerate(ex['pos']):\n",
    "            f = 'pos=%s' % w\n",
    "            if f in feature_dict:\n",
    "                features[i][feature_dict[f]] = 1.0\n",
    "    # f_{token} (NER)\n",
    "    if args.use_ner:\n",
    "        for i, w in enumerate(ex['ner']):\n",
    "            f = 'ner=%s' % w\n",
    "            if f in feature_dict:\n",
    "                features[i][feature_dict[f]] = 1.0\n",
    "                \n",
    "    # f_{token} (TF)\n",
    "    if args.use_tf:\n",
    "        counter = Counter([w.lower() for w in ex['document']])\n",
    "        l = len(ex['document'])\n",
    "        for i, w in enumerate(ex['document']):\n",
    "            features[i][feature_dict['tf']] = counter[w.lower()] * 1.0 / l\n",
    "\n",
    "    # Maybe return without target\n",
    "    if 'answers' not in ex:\n",
    "        return document, features, question, ex['id']\n",
    "\n",
    "    # ...or with target(s) (might still be empty if answers is empty)\n",
    "    if single_answer:\n",
    "        assert(len(ex['answers']) > 0)\n",
    "        start = torch.LongTensor(1).fill_(ex['answers'][0][0])\n",
    "        end = torch.LongTensor(1).fill_(ex['answers'][0][1])\n",
    "    else:\n",
    "        start = [a[0] for a in ex['answers']]\n",
    "        end = [a[1] for a in ex['answers']]\n",
    "        \n",
    "    return document, features, question, start, end, ex['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
